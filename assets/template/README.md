# Python template for LLM inference on remote server

```sh
python main.py
```

반드시 `config.py`를 확인 후 실행하세요.
