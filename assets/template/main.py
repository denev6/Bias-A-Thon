"""Example: 5-shot learning with reasoning"""

import ast
import time

from config import *
from model import Model, set_cuda, collect_garbage
from prompt import (
    preprocess,
    generate_prompt,
    split_answer,
    extract_last_choice,
)
from utils import ignore_warnings, load_data, save_data, join_path


# ìˆ˜í–‰í•  ì‘ì—…
def pipeline(model, batch_prompts, max_new_tokens) -> list[str]:
    question_tokens = model.tokenize_batch(batch_prompts)
    answer_tokens = model.process_batch(question_tokens, max_new_tokens)
    return answer_tokens


print("ğŸ”¥ì„¤ì • ì¤€ë¹„ ì¤‘...")
if IGNORE_WARNING:
    ignore_warnings()

# CUDA ì„¤ì •
device = set_cuda(RANDOM_SEED)

# Llama3
print("ğŸ”¥ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
our_llm = Model(
    join_path(MODEL_DIR),
    device=device,
    max_length=TOKENIZER_MAX_LENGTH,
    do_sample=DO_SAMPLE,
    temperature=TEMPERATURE,
    top_k=TOP_K,
    skip_special_tokens=SKIP_SPECIAL_TOKENS,
    device_map=MODEL_DEVICE_MAP,
)

# ë°ì´í„° ì¤€ë¹„
file_prefix = "submit"

df_original, df_check_point, start_idx = load_data(
    path=join_path(INPUT_CSV),
    cols=["ID", "raw_input", "raw_output", "answer"],
    checkpoint_dir=join_path(CHECKPOINT_DIR),
    last_checkpoint=LAST_INFERENCE_CHECK_POINT,
    prefix=file_prefix,
)
total_data_size = len(df_check_point)

# ë§ˆìŠ¤í‚¹ëœ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
prompts = preprocess(
    df_original,
    function=generate_prompt,
    num_workers=NUM_WORKERS,
)

# ì¶”ë¡  ë° ì €ì¥
print("ğŸ”¥ëª¨ë¸ ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
collect_garbage()

start_time = time.time()
while start_idx < total_data_size:
    end_idx = min(start_idx + BATCH_SIZE, total_data_size)
    batch_prompts = prompts[start_idx:end_idx]
    batch_answers = pipeline(our_llm, batch_prompts, max_new_tokens=MAX_NEW_TOKENS)

    for idx, answer in enumerate(batch_answers):
        idx = idx + start_idx
        prompt, raw_answer = split_answer(answer)
        df_check_point.at[idx, "raw_input"] = prompt
        df_check_point.at[idx, "raw_output"] = raw_answer
        choices = ast.literal_eval(df_original.at[idx, "choices"])
        df_check_point.at[idx, "answer"] = extract_last_choice(raw_answer, choices)

        if idx % CHECK_POINT_STEP == 0:
            # Check pointì—ì„œ ë‹µë³€ì„ íŒŒì¼ë¡œ ì €ì¥
            end_time = time.time()
            save_data(
                df_check_point,
                cols=["ID", "raw_input", "raw_output", "answer"],
                path=join_path(CHECKPOINT_DIR, f"{file_prefix}_{str(idx)}.csv"),
            )
            print(f"âœ…[{idx}/{total_data_size}] {(end_time - start_time) / 60:.1f}ë¶„")
            start_time = time.time()

    start_idx = end_idx


# ìµœì¢… íŒŒì¼ ì €ì¥
save_data(
    df_check_point,
    cols=["ID", "raw_input", "raw_output", "answer"],
    path=join_path(FINAL_CSV),
)
print("\nğŸ« ê¸°ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
