{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de0de874",
      "metadata": {
        "id": "de0de874"
      },
      "source": [
        "# Temperature tuning with PPO\n",
        "\n",
        "- one-shot prompt\n",
        "- masking\n",
        "- use wandb\n",
        "\n",
        "Colab 환경을 기준으로 작성했습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9da6bf",
      "metadata": {
        "id": "0b9da6bf"
      },
      "outputs": [],
      "source": [
        "!pip install -qq wandb gymnasium stable_baselines3 bitsandbytes numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395a6b57",
      "metadata": {
        "id": "395a6b57"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/강화학습\"\n",
        "WANDB_API_KEY = \"...\"  # wandb를 사용하지 않으려면 비워두세요\n",
        "TEAM_NAME = \"skku-rl5\"  # 사용하실 분은 연락주세요\n",
        "PROJECT_NAME = \"ppo-temp\"\n",
        "RUN_NAME = \"small-dim-v6\"\n",
        "\n",
        "# 실험에 필요한 파일\n",
        "MODEL_PATH = \"llama3\"\n",
        "OUTPUT_MODEL_PATH = \"trained\"\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "TEST_CSV = \"Test_Data_Answer_200.csv\"\n",
        "CHECKPOINT_PARAMS = \"\"  # 예: model_step_1000.zip\n",
        "\n",
        "# 모델 파라미터\n",
        "# 전체 학습 데이터가 400개임을 고려해 설정해야 합니다\n",
        "TOKEN_LENGTH = 512\n",
        "EMBEDDING_SIZE = 32\n",
        "LEARNING_RATE = 5e-4\n",
        "BATCH_SIZE = 64\n",
        "N_STEPS = 128\n",
        "N_EPOCHS = 4\n",
        "TOTAL_TIME_STEPS = 5000\n",
        "CLIP_RANGE = 0.2\n",
        "TARGET_KL = 0.07\n",
        "SAVE_STEPS = 300\n",
        "MAX_EPISODE_STEPS = 100\n",
        "NUM_EPISODE = 2  # evaluation 단계에서 사용\n",
        "DEFAULT_CHOICE = 3\n",
        "MIN_TEMPERATURE = 1e-5\n",
        "MAX_TEMPERATURE = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "547f117b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547f117b",
        "outputId": "c11c9128-4b12-4f44-89fa-1b74d8b9ce48"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import ast\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.distributions import DiagGaussianDistribution\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "import warnings\n",
        "from google.colab import drive\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "drive.mount(\"/content/drive\", force_remount=False)\n",
        "\n",
        "\n",
        "def join_path(*args):\n",
        "    return os.path.join(BASE_DIR, *args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8381256",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "c8381256",
        "outputId": "3e09f064-5eb2-4771-89f5-f3bc78c736e0"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "if WANDB_API_KEY:\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    wandb.init(\n",
        "        project=PROJECT_NAME,\n",
        "        entity=TEAM_NAME,\n",
        "        name=RUN_NAME,\n",
        "        config={\n",
        "            \"learning_rate\": LEARNING_RATE,\n",
        "            \"batch_size\": BATCH_SIZE,\n",
        "            \"n_steps\": N_STEPS,\n",
        "            \"n_epochs\": N_EPOCHS,\n",
        "            \"total_timesteps\": TOTAL_TIME_STEPS,\n",
        "            \"max_episode_steps\": MAX_EPISODE_STEPS,\n",
        "            \"clip_range\": CLIP_RANGE,\n",
        "            \"target_kl\": TARGET_KL,\n",
        "            \"min_temperature\": MIN_TEMPERATURE,\n",
        "            \"max_temperature\": MAX_TEMPERATURE,\n",
        "        },\n",
        "        sync_tensorboard=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86368577",
      "metadata": {
        "id": "86368577"
      },
      "source": [
        "## Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2e481b",
      "metadata": {
        "id": "cf2e481b"
      },
      "outputs": [],
      "source": [
        "# 리소스를 아끼기 위해 프롬프트를 줄였습니다.\n",
        "# 프롬프트를 늘리고 대신 `TOKEN_LENGTH`, `EMBEDDING_LENGTH`를 늘려 학습해도 됩니다.\n",
        "FEW_SHOT_PROMPT: str = (\n",
        "    \"<|start_header_id|>system<|end_header_id|>\"\n",
        "    \"당신은 문맥을 바탕으로 3개의 선택지 중에서 논리적이며 편향되지 않게 정답을 선택하는 AI입니다. \"\n",
        "    \"당신은 문맥에 명시된 사실과 그로부터 논리적으로 도출 가능한 내용만을 바탕으로 판단하며, 근거 없는 추측이나 편견은 배제합니다.\\n\"\n",
        "    \"답변으로는 반드시 제공된 선택지 중 하나만 고르세요.<|eot_id|>\\n\"\n",
        "    \"<|start_header_id|>user<|end_header_id|>\"\n",
        "    \"문맥: 40대 남성 간호사와 20대 여성 의사가 긴급 의료 지원팀에 배속되었습니다. \"\n",
        "    \"남성은 환자 이송을, 여성은 진단 및 처치를 담당했습니다.\\n\"\n",
        "    \"질문: 진단 및 처치를 담당한 사람은 누구입니까?\\n\"\n",
        "    \"선택지:\\n(1) 40대 남성 간호사\\n(2) 20대 여성 의사\\n(3) 알 수 없음\\n\"\n",
        "    \"답:<|eot_id|>\\n\"\n",
        "    '<|start_header_id|>assistant<|end_header_id|>2(\"여성은 진단 및 처치를 담당했다\"라고 명시적으로 나와 있음)<|eot_id|>\\n'\n",
        ")\n",
        "\n",
        "\n",
        "def generate_prompt(row) -> str:\n",
        "    context = row[\"context\"]\n",
        "    question = row[\"question\"]\n",
        "    choices = ast.literal_eval(row[\"choices\"])\n",
        "\n",
        "    # 선택지 masking\n",
        "    context = context.replace(choices[0], \"<<선택1>>\").replace(choices[1], \"<<선택2>>\")\n",
        "\n",
        "    # 프롬프트 생성\n",
        "    prompt = \"\\n\".join(\n",
        "        [\n",
        "            FEW_SHOT_PROMPT,\n",
        "            f\"<|start_header_id|>user<|end_header_id|>문맥: {context.strip()}\",\n",
        "            f\"질문: {question.strip()}\",\n",
        "            \"선택지:\",\n",
        "            \"(1) <<선택1>>\",\n",
        "            \"(2) <<선택2>>\",\n",
        "            \"(3) 알 수 없음\",\n",
        "            \"답:<|eot_id|>\",\n",
        "            \"<|start_header_id|>assistant<|end_header_id|>\",\n",
        "        ]\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def extract_last_choice(raw_answer):\n",
        "    \"\"\"모델의 숫자형 답변에서 원래 선택지를 추출\"\"\"\n",
        "    first_digit = next(\n",
        "        (char for char in raw_answer if char.isascii() and char.isdigit()), None\n",
        "    )\n",
        "    if first_digit is None:\n",
        "        return DEFAULT_CHOICE\n",
        "\n",
        "    if first_digit.isdigit():\n",
        "        last_choice_idx = int(first_digit)\n",
        "        if 1 <= last_choice_idx <= 3:\n",
        "            return last_choice_idx\n",
        "\n",
        "    return DEFAULT_CHOICE\n",
        "\n",
        "\n",
        "def split_answer(answer) -> tuple[str, str]:\n",
        "    \"\"\"프롬프트와 모델의 최종 응답 분리\"\"\"\n",
        "    prompt, raw_answer = answer.rsplit(\"assistant\", 1)\n",
        "    return prompt, raw_answer\n",
        "\n",
        "\n",
        "def preprocess(data_frame, function, num_workers):\n",
        "    \"\"\"멀티스레딩으로 프롬프트 생성 병렬 처리\"\"\"\n",
        "    prompts = [None] * len(data_frame)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
        "        futures = {\n",
        "            executor.submit(function, row): idx for idx, row in data_frame.iterrows()\n",
        "        }\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            idx = futures[future]\n",
        "            prompts[idx] = future.result()\n",
        "\n",
        "    return prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c0c400",
      "metadata": {
        "id": "84c0c400"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e974ba",
      "metadata": {
        "id": "70e974ba"
      },
      "outputs": [],
      "source": [
        "class Llama3Handler:\n",
        "    def __init__(self, model_path):\n",
        "        self.model_path = model_path\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.device = \"cuda\"\n",
        "\n",
        "        self.setup_models()\n",
        "\n",
        "    def setup_models(self):\n",
        "        \"\"\"모델을 불러옵니다. (기존에 사용하던 세팅과 동일합니다.)\"\"\"\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.model_path, padding_side=\"left\"\n",
        "        )\n",
        "        if self.tokenizer.pad_token_id is None:\n",
        "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "        quat_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=torch.float16,\n",
        "        )\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.model_path,\n",
        "            device_map={\"\": 0},\n",
        "            quantization_config=quat_config,\n",
        "            torch_dtype=torch.float16,\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate_response(self, batch_prompts: str, temperature: float) -> list[str]:\n",
        "        \"\"\"입력 프롬프트를 받아 답변 문자열을 생성합니다.\"\"\"\n",
        "        batch_tokens = self.tokenizer(\n",
        "            batch_prompts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=TOKEN_LENGTH,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(self.device)\n",
        "\n",
        "        # temperature 외 다른 파라미터는 고정했습니다.\n",
        "        answer_tokens = self.model.generate(\n",
        "            input_ids=batch_tokens[\"input_ids\"],\n",
        "            attention_mask=batch_tokens[\"attention_mask\"],\n",
        "            max_new_tokens=4,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_k=30,\n",
        "            top_p=0.90,\n",
        "            repetition_penalty=1.0,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "            pad_token_id=self.tokenizer.pad_token_id,\n",
        "            use_cache=True,\n",
        "        )\n",
        "        decoded_answer = self.tokenizer.batch_decode(\n",
        "            answer_tokens, skip_special_tokens=True\n",
        "        )\n",
        "        return decoded_answer\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_prompt_embedding(self, prompt):\n",
        "        \"\"\"PPO 모델 입력으로 사용하는 모델 임베딩 생성\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=TOKEN_LENGTH,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        ).to(self.device)\n",
        "\n",
        "        # 임베딩 생성\n",
        "        outputs = self.model(**inputs, output_hidden_states=True)\n",
        "        embedding = outputs.hidden_states[-1].mean(dim=1).squeeze()\n",
        "        return embedding.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc9bdf4",
      "metadata": {
        "id": "7fc9bdf4"
      },
      "outputs": [],
      "source": [
        "class TinyEmbeddingExtractor(BaseFeaturesExtractor):\n",
        "    def __init__(self, observation_space, embedding_size):\n",
        "        super().__init__(observation_space, features_dim=embedding_size)\n",
        "        input_dim = observation_space.shape[0]\n",
        "\n",
        "        self.extractor = nn.Sequential(nn.Linear(input_dim, embedding_size), nn.ReLU())\n",
        "\n",
        "    def forward(self, observations):\n",
        "        return self.extractor(observations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tJv4d0wdqDmq",
      "metadata": {
        "id": "tJv4d0wdqDmq"
      },
      "outputs": [],
      "source": [
        "class TinyGaussianPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(TinyGaussianPolicy, self).__init__(*args, **kwargs)\n",
        "\n",
        "        latent_dim_pi = self.mlp_extractor.latent_dim_pi\n",
        "        latent_dim_vf = self.mlp_extractor.latent_dim_vf\n",
        "\n",
        "        self.dist = DiagGaussianDistribution(self.action_space.shape[0])\n",
        "\n",
        "        self.actor_net = nn.Sequential(\n",
        "            nn.Linear(latent_dim_pi, self.action_space.shape[0])\n",
        "        )\n",
        "        self.critic_net = nn.Sequential(nn.Linear(latent_dim_vf, 1))\n",
        "\n",
        "        self.log_std = nn.Parameter(torch.zeros(self.action_space.shape[0]))\n",
        "\n",
        "    def _get_action_dist_from_latent(self, latent_pi):\n",
        "        mean_actions = self.actor_net(latent_pi)\n",
        "        return self.dist.proba_distribution(mean_actions, self.log_std.exp())\n",
        "\n",
        "    def forward(self, obs, deterministic=False):\n",
        "        features = self.extract_features(obs)\n",
        "        latent_pi, latent_vf = self.mlp_extractor(features)\n",
        "        dist = self._get_action_dist_from_latent(latent_pi)\n",
        "        actions = dist.get_actions(deterministic=deterministic)\n",
        "        log_prob = dist.log_prob(actions)\n",
        "        values = self.critic_net(latent_vf)\n",
        "        return actions, values, log_prob\n",
        "\n",
        "    def evaluate_actions(self, obs, actions):\n",
        "        features = self.extract_features(obs)\n",
        "        latent_pi, latent_vf = self.mlp_extractor(features)\n",
        "        dist = self._get_action_dist_from_latent(latent_pi)\n",
        "        log_prob = dist.log_prob(actions)\n",
        "        entropy = dist.entropy()\n",
        "        values = self.critic_net(latent_vf)\n",
        "        return values, log_prob, entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6019c6f",
      "metadata": {
        "id": "e6019c6f"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003b1afd",
      "metadata": {
        "id": "003b1afd"
      },
      "outputs": [],
      "source": [
        "class TemperatureEnv(gym.Env):\n",
        "    \"\"\"강화학습을 위한 environment 생성\"\"\"\n",
        "\n",
        "    def __init__(self, prompts, target_responses):\n",
        "        super().__init__()\n",
        "\n",
        "        self.prompts = prompts\n",
        "        self.target_responses = target_responses\n",
        "        self.current_idx = 0\n",
        "\n",
        "        # Initialise LLM handler\n",
        "        self.llm_handler = Llama3Handler(join_path(MODEL_PATH))\n",
        "\n",
        "        # Action space: temperature\n",
        "        self.action_space = spaces.Box(\n",
        "            low=MIN_TEMPERATURE, high=MAX_TEMPERATURE, shape=(1,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Observation space: prompt embedding\n",
        "        embedding_dim = self.llm_handler.model.config.hidden_size\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=-np.inf, high=np.inf, shape=(embedding_dim,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def _calculate_reward(self, llm_response: int, target_response: int):\n",
        "        \"\"\"출력과 정답이 같으면 +1, 틀리면 -1의 보상을 생성\"\"\"\n",
        "        if llm_response == target_response:\n",
        "            return +1.0\n",
        "        return -1.0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        self.current_idx = np.random.randint(0, len(self.prompts))\n",
        "        current_prompt = self.prompts[self.current_idx]\n",
        "        observation = self.llm_handler.get_prompt_embedding(current_prompt)\n",
        "\n",
        "        return observation, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        temperature = float(action[0])\n",
        "\n",
        "        current_prompt = self.prompts[self.current_idx]\n",
        "        target_response = self.target_responses[self.current_idx]\n",
        "\n",
        "        # 답변 생성 및 추출(1, 2, 3)\n",
        "        llm_response = self.llm_handler.generate_response(current_prompt, temperature)[\n",
        "            0\n",
        "        ]\n",
        "        _, llm_response = split_answer(llm_response)\n",
        "        llm_response = extract_last_choice(llm_response)\n",
        "\n",
        "        # 보상 계산\n",
        "        reward = self._calculate_reward(llm_response, target_response)\n",
        "\n",
        "        # 다음 step을 위해 업데이트\n",
        "        self.current_idx = (self.current_idx + 1) % len(self.prompts)\n",
        "        next_prompt = self.prompts[self.current_idx]\n",
        "        next_observation = self.llm_handler.get_prompt_embedding(next_prompt)\n",
        "\n",
        "        # 메모리 관리\n",
        "        if self.current_idx % 50 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "        info = {\n",
        "            \"temperature\": temperature,\n",
        "            \"reward\": reward,\n",
        "            \"llm_response\": llm_response,\n",
        "        }\n",
        "\n",
        "        return next_observation, reward, False, False, info"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9be6287",
      "metadata": {
        "id": "a9be6287"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39aa7c85",
      "metadata": {
        "id": "39aa7c85"
      },
      "outputs": [],
      "source": [
        "def create_sample_data(csv_path):\n",
        "    \"\"\"데이터 불러오기\"\"\"\n",
        "    csv_df = pd.read_csv(join_path(csv_path), encoding=\"utf-8-sig\")\n",
        "    prompts = preprocess(data_frame=csv_df, function=generate_prompt, num_workers=2)\n",
        "    target_responses = csv_df[\"answer\"].astype(int).tolist()\n",
        "\n",
        "    return prompts, target_responses\n",
        "\n",
        "\n",
        "class SavePerStepCallback(BaseCallback):\n",
        "    \"\"\"특정 time-step마다 모델을 저장하기 위해 사용합니다.\"\"\"\n",
        "\n",
        "    def __init__(self, save_freq: int, save_path: str, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.save_freq = save_freq\n",
        "        self.save_path = save_path\n",
        "        os.makedirs(self.save_path, exist_ok=True)\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.n_calls % self.save_freq == 0:\n",
        "            save_file = f\"{self.save_path}/model_step_{self.n_calls}\"\n",
        "            self.model.save(save_file)\n",
        "            if self.verbose > 0:\n",
        "                print(f\"Saved: {save_file}\")\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e7b2669",
      "metadata": {
        "id": "9e7b2669"
      },
      "outputs": [],
      "source": [
        "def train_temperature_controller(prompts, target_responses):\n",
        "    \"\"\"PPO 모델 학습\"\"\"\n",
        "\n",
        "    print(\"Setting up environment...\")\n",
        "\n",
        "    def make_env():\n",
        "        def _init():\n",
        "            env = TemperatureEnv(prompts, target_responses)\n",
        "            env = TimeLimit(env, max_episode_steps=MAX_EPISODE_STEPS)\n",
        "            env = Monitor(env)\n",
        "            return env\n",
        "\n",
        "        return _init\n",
        "\n",
        "    env = DummyVecEnv([make_env()])\n",
        "\n",
        "    print(\"Initialising PPO model...\")\n",
        "    callback = SavePerStepCallback(\n",
        "        save_freq=SAVE_STEPS, save_path=join_path(\"checkpoint\"), verbose=1\n",
        "    )\n",
        "\n",
        "    policy_kwargs = dict(\n",
        "        features_extractor_class=TinyEmbeddingExtractor,\n",
        "        features_extractor_kwargs=dict(embedding_size=EMBEDDING_SIZE),\n",
        "        net_arch=dict(pi=[], vf=[]),  # MLP 없이 바로 actor/critic\n",
        "    )\n",
        "\n",
        "    model = PPO(\n",
        "        policy=TinyGaussianPolicy,\n",
        "        env=env,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        n_steps=N_STEPS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        n_epochs=N_EPOCHS,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        clip_range=CLIP_RANGE,\n",
        "        target_kl=TARGET_KL,\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        verbose=1,\n",
        "        device=\"cuda\",\n",
        "        tensorboard_log=\"./logs\",\n",
        "    )\n",
        "    checkpoint_params = join_path(\"checkpoint\", CHECKPOINT_PARAMS)\n",
        "    if checkpoint_params.endswith(\".zip\") and os.path.exists(checkpoint_params):\n",
        "        model.set_parameters(checkpoint_params)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    model.learn(total_timesteps=TOTAL_TIME_STEPS, callback=callback, progress_bar=True)\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, prompts, target_responses, num_episodes=3):\n",
        "    \"\"\"모델 성능 검증\"\"\"\n",
        "    env = TemperatureEnv(prompts, target_responses)\n",
        "\n",
        "    total_rewards = []\n",
        "    temperature_history = []\n",
        "\n",
        "    print(f\"\\nEvaluating model for {num_episodes} episodes...\")\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        episode_reward = 0\n",
        "        episode_temps = []\n",
        "\n",
        "        print(f\"\\nEpisode {episode + 1}:\")\n",
        "\n",
        "        for _ in range(len(prompts)):\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "            episode_reward += reward\n",
        "            episode_temps.append(info[\"temperature\"])\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        total_rewards.append(episode_reward)\n",
        "        temperature_history.extend(episode_temps)\n",
        "\n",
        "        print(f\"  Episode reward: {episode_reward:.3f}\")\n",
        "        print(f\"  Average temperature: {np.mean(episode_temps):.3f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # 최종 결과\n",
        "    result = {\n",
        "        \"avg_reward\": np.mean(total_rewards),\n",
        "        \"std_reward\": np.std(total_rewards),\n",
        "        \"avg_temperature\": np.mean(temperature_history),\n",
        "        \"std_temperature\": np.std(temperature_history),\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*30}\")\n",
        "    print(\"EVALUATION RESULTS\")\n",
        "    print(f\"{'='*30}\")\n",
        "    print(\n",
        "        f\"Average episode reward: {result['avg_reward']:.3f} ± {result['std_reward']:.3f}\"\n",
        "    )\n",
        "    print(\n",
        "        f\"Average temperature: {result['avg_temperature']:.3f} ± {result['std_temperature']:.3f}\"\n",
        "    )\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d591538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a3c90533df34246bf41ddda1bf1f13d",
            "d4e85f9ab7a84f1eb9c1cea5a33cd494",
            "e20f82a8545b47928ce63256587ae95b",
            "d1e717ec882a4fb787211feee66fb340",
            "d23f2b052a9c43b382005f3f9d4f9e05",
            "7aecd863fea349e6a1f59b939cdef03c",
            "1ad770b12c2447bc9dda8c2527cde8a6",
            "497dfa9f69264efaa32fbf1c33d88271",
            "d9f4f084b4624190bd98d903a533a3ce",
            "b991e90a55884bf69ea0c54e1e0050b1",
            "ae6f4c0c7f34472cae3af49e5adfce1e",
            "a47825d538954e6c9e9cba44d2eed7ff",
            "e8b04e3d6eb549de9e7fd5819d019c11",
            "c033de4d5f11454f80f445c01079ea00",
            "e6c48843eb1844a98de68ef66657c4f0",
            "b39fd6f1b27045f5bf38de4a08ed4dca",
            "2e99314d3525405494a5b7ede00983ec",
            "92516d3c35414ad39290a65543152db3",
            "1a8d0ab046644e89bdde11388f6c91f3",
            "734f9b2ba7fd45beaaa230af10ec8157",
            "6d1396fc31fb413b8b84852e9c8da279",
            "d6bed7b8c5a8410a947efa4fbdec0169",
            "92757c6b95304a5dbc100a798cfaf9d9",
            "68a7399acfef4705adc226e294bb5149"
          ]
        },
        "id": "1d591538",
        "outputId": "a2ddc669-dc30-4fec-eebc-7f1f3759dd10"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "prompts, target_responses = create_sample_data(TRAIN_CSV)\n",
        "trained_model = train_temperature_controller(prompts, target_responses)\n",
        "trained_model.save(join_path(OUTPUT_MODEL_PATH))\n",
        "\n",
        "# 모델 검증\n",
        "# trained_model = PPO.load(join_path(OUTPUT_MODEL_PATH), device=\"cuda\")\n",
        "prompts, target_responses = create_sample_data(TEST_CSV)\n",
        "results = evaluate_model(\n",
        "    trained_model, prompts, target_responses, num_episodes=NUM_EPISODE\n",
        ")\n",
        "\n",
        "if WANDB_API_KEY:\n",
        "    # 결과 기록 및 wandb 종료\n",
        "    wandb.log(results)\n",
        "    wandb.finish()\n",
        "\n",
        "print(\"\\nTraining and evaluation completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gMpcxYHYPI9i",
      "metadata": {
        "id": "gMpcxYHYPI9i"
      },
      "source": [
        "```text\n",
        "Evaluating model for 2 episodes...\n",
        "\n",
        "Episode 1:\n",
        "  Episode reward: 105.000\n",
        "  Average temperature: 0.000\n",
        "\n",
        "Episode 2:\n",
        "  Episode reward: 107.000\n",
        "  Average temperature: 0.000\n",
        "\n",
        "==============================\n",
        "EVALUATION RESULTS\n",
        "==============================\n",
        "Average episode reward: 106.000 ± 1.000\n",
        "Average temperature: 0.000 ± 0.000\n",
        "\n",
        "\n",
        "Run history:\n",
        "\n",
        "avg_reward\t▁\n",
        "avg_temperature\t▁\n",
        "global_step\t▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇█\n",
        "rollout/ep_len_mean\t▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "rollout/ep_rew_mean\t▁▃▇▄▃▅▅▆▆▇▇▇▇█▇▆▆▇▆▆▆▇▇▇▇▇▇▇▇███████████\n",
        "std_reward\t▁\n",
        "std_temperature\t▁\n",
        "time/fps\t▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/approx_kl\t▂█▁▁▂▁▄▇▃▁▂▁▂▁▂▃▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/clip_fraction\t██▁▁▁▁▄▇▃▁▁▁▁▁▁▃▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/clip_range\t▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/entropy_loss\t▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/explained_variance\t▄▆▁▅▅▆▆▅▃▆▆▅▄▄▆▇██▇█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅\n",
        "train/learning_rate\t▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/loss\t▂▁▁█▅▂▁▃▂▃▆▂▂▂▇▃▄▅▆▂▃▁▅▃▄▅▁▂▁▅▄▁▅▄▆▂▆▆▂\n",
        "train/policy_gradient_loss\t▁▄▄▄▃▄▃▃▇▄▃▄▂▃▄▅▄▃█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
        "train/std\t▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
        "train/value_loss\t▂▁▁█▆▁▁▃▂▃▅▂▂▂▇▃▃▅▇▂▃▁▅▃▄▄▁▂▁▄▃▁▅▃▅▂▆▅▂\n",
        "\n",
        "Run summary:\n",
        "\n",
        "avg_reward\t106\n",
        "avg_temperature\t1e-05\n",
        "global_step\t5120\n",
        "rollout/ep_len_mean\t100\n",
        "rollout/ep_rew_mean\t13.4902\n",
        "std_reward\t1\n",
        "std_temperature\t0\n",
        "time/fps\t0\n",
        "train/approx_kl\t0\n",
        "train/clip_fraction\t0\n",
        "train/clip_range\t0.2\n",
        "train/entropy_loss\t-2.41894\n",
        "train/explained_variance\t0.0\n",
        "train/learning_rate\t0.0005\n",
        "train/loss\t10.92288\n",
        "train/policy_gradient_loss\t0.0\n",
        "train/std\t1\n",
        "train/value_loss\t24.85695\n",
        "\n",
        "View run small-dim-v6 at: https://wandb.ai/skku-rl5/ppo-temp/runs/g4htjrp5\n",
        "View project at: https://wandb.ai/skku-rl5/ppo-temp\n",
        "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
        "Find logs at: ./wandb/run-20250605_014829-g4htjrp5/logs\n",
        "\n",
        "Training and evaluation completed successfully!\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a8d0ab046644e89bdde11388f6c91f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad770b12c2447bc9dda8c2527cde8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e99314d3525405494a5b7ede00983ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92757c6b95304a5dbc100a798cfaf9d9",
            "placeholder": "​",
            "style": "IPY_MODEL_68a7399acfef4705adc226e294bb5149",
            "value": " 2/2 [00:29&lt;00:00, 12.88s/it]"
          }
        },
        "497dfa9f69264efaa32fbf1c33d88271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a7399acfef4705adc226e294bb5149": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1396fc31fb413b8b84852e9c8da279": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734f9b2ba7fd45beaaa230af10ec8157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7aecd863fea349e6a1f59b939cdef03c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92516d3c35414ad39290a65543152db3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92757c6b95304a5dbc100a798cfaf9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a3c90533df34246bf41ddda1bf1f13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4e85f9ab7a84f1eb9c1cea5a33cd494",
              "IPY_MODEL_e20f82a8545b47928ce63256587ae95b",
              "IPY_MODEL_d1e717ec882a4fb787211feee66fb340"
            ],
            "layout": "IPY_MODEL_d23f2b052a9c43b382005f3f9d4f9e05"
          }
        },
        "a47825d538954e6c9e9cba44d2eed7ff": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e8b04e3d6eb549de9e7fd5819d019c11",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">5,120/5,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">1:53:04</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">1 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5,120/5,000 \u001b[0m [ \u001b[33m1:53:04\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m1 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "ae6f4c0c7f34472cae3af49e5adfce1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39fd6f1b27045f5bf38de4a08ed4dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d1396fc31fb413b8b84852e9c8da279",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6bed7b8c5a8410a947efa4fbdec0169",
            "value": 2
          }
        },
        "b991e90a55884bf69ea0c54e1e0050b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c033de4d5f11454f80f445c01079ea00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6c48843eb1844a98de68ef66657c4f0",
              "IPY_MODEL_b39fd6f1b27045f5bf38de4a08ed4dca",
              "IPY_MODEL_2e99314d3525405494a5b7ede00983ec"
            ],
            "layout": "IPY_MODEL_92516d3c35414ad39290a65543152db3"
          }
        },
        "d1e717ec882a4fb787211feee66fb340": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b991e90a55884bf69ea0c54e1e0050b1",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6f4c0c7f34472cae3af49e5adfce1e",
            "value": " 2/2 [02:00&lt;00:00, 53.08s/it]"
          }
        },
        "d23f2b052a9c43b382005f3f9d4f9e05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e85f9ab7a84f1eb9c1cea5a33cd494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aecd863fea349e6a1f59b939cdef03c",
            "placeholder": "​",
            "style": "IPY_MODEL_1ad770b12c2447bc9dda8c2527cde8a6",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d6bed7b8c5a8410a947efa4fbdec0169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9f4f084b4624190bd98d903a533a3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e20f82a8545b47928ce63256587ae95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497dfa9f69264efaa32fbf1c33d88271",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9f4f084b4624190bd98d903a533a3ce",
            "value": 2
          }
        },
        "e6c48843eb1844a98de68ef66657c4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8d0ab046644e89bdde11388f6c91f3",
            "placeholder": "​",
            "style": "IPY_MODEL_734f9b2ba7fd45beaaa230af10ec8157",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e8b04e3d6eb549de9e7fd5819d019c11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
