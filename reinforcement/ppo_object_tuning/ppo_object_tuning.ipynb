{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPK29-_gQRgX"
   },
   "source": [
    "<h1> PPO ë°©ì‹ì„ í™œìš©í•œ Object(temperature + top p) íŠœë‹ </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1748174069003,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "IEAYk5HaJcUv"
   },
   "outputs": [],
   "source": [
    "# âœ… config ì„¤ì •\n",
    "BASE_DIR = \"/content/drive/MyDrive/RL/temperature_adjustment\"\n",
    "TEST_CSV = \"../test.csv\"\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "ANSWER_CSV = \"answer.csv\"\n",
    "MODEL_DIR = \"../llama3\"\n",
    "CHECKPOINT_DIR = \"checkpoint\"\n",
    "MODEL_DEVICE_MAP = \"sequential\"\n",
    "LAST_INFERENCE_CHECK_POINT = 0\n",
    "BATCH_SIZE = 16\n",
    "DEFAULT_CHOICE = \"ì•Œ ìˆ˜ ì—†ìŒ\"\n",
    "NUM_WORKERS = 2\n",
    "IGNORE_WARNING = True\n",
    "SKIP_SPECIAL_TOKENS = True\n",
    "DO_SAMPLE = True\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.90\n",
    "TOP_K = 30\n",
    "REPETITION_PENALTY = 1.0\n",
    "MAX_NEW_TOKENS = 64\n",
    "TOKENIZER_MAX_LENGTH = 2048\n",
    "CHECK_POINT_STEP = 100\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYt-DuctQmpF"
   },
   "source": [
    "# ëª¨ë¸ ë° í”„ë¡¬í”„íŠ¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1397,
     "status": "ok",
     "timestamp": 1748175072485,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "3zIuiHU5WFS6",
    "outputId": "66918c88-c9cd-4d16-ebc8-d41cbd420412"
   },
   "outputs": [],
   "source": [
    "import os, gc, torch, time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from google.colab import drive\n",
    "\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=False)\n",
    "\n",
    "\n",
    "def join_path(*args):\n",
    "    return os.path.join(BASE_DIR, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1748170472240,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "t4_ciITaUpoH"
   },
   "outputs": [],
   "source": [
    "def set_cuda(random_seed):\n",
    "    assert torch.cuda.is_available(), \"CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\"\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    if hasattr(torch.backends.cuda, \"matmul\"):\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    return \"cuda\"\n",
    "\n",
    "def collect_garbage():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, path, device, max_length, do_sample, temperature=0.6,\n",
    "                 top_k=30, top_p=0.9, repetition_penalty=1.0,\n",
    "                 skip_special_tokens=True, device_map=\"auto\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(path, padding_side=\"left\")\n",
    "        if self.tokenizer.pad_token_id is None:\n",
    "            self.tokenizer.pad_token_id = self.tokenizer.eos_token_id\n",
    "        quat_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True,\n",
    "                                         bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            path, device_map=device_map, quantization_config=quat_config, torch_dtype=torch.float16\n",
    "        )\n",
    "        self.max_length = max_length\n",
    "        self.do_sample = do_sample\n",
    "        self.temperature = temperature\n",
    "        self.top_k = top_k\n",
    "        self.top_p = top_p\n",
    "        self.repetition_penalty = repetition_penalty\n",
    "        self.skip_special_tokens = skip_special_tokens\n",
    "        self.device = device\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tokenize_batch(self, batch_prompts):\n",
    "        return self.tokenizer(batch_prompts, padding=True, truncation=True,\n",
    "                              max_length=self.max_length, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def process_batch(self, batch_tokens, max_new_tokens):\n",
    "        output = self.model.generate(\n",
    "            input_ids=batch_tokens[\"input_ids\"],\n",
    "            attention_mask=batch_tokens[\"attention_mask\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=self.do_sample,\n",
    "            temperature=self.temperature,\n",
    "            top_k=self.top_k,\n",
    "            top_p=self.top_p,\n",
    "            repetition_penalty=self.repetition_penalty,\n",
    "            eos_token_id=self.tokenizer.eos_token_id,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            use_cache=True,\n",
    "        )\n",
    "        return self.tokenizer.batch_decode(output, skip_special_tokens=self.skip_special_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1748170472256,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "8q9iezB1Jhe-"
   },
   "outputs": [],
   "source": [
    "## 3 ì²´ì¸ í”„ë¡¬í”„íŠ¸ + íœ´ë¨¼ í˜ë¥´ì†Œë‚˜ ì ìš©\n",
    "\n",
    "import ast, re\n",
    "\n",
    "\n",
    "def generate_system_prompt() -> str:\n",
    "    return (\n",
    "        \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\"\n",
    "        \"ë‹¹ì‹ ì€ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ 3ê°œì˜ ì„ íƒì§€ ì¤‘ì—ì„œ ë…¼ë¦¬ì ì´ë©° í¸í–¥ë˜ì§€ ì•Šê²Œ ì •ë‹µì„ ì„ íƒí•˜ëŠ” AIì…ë‹ˆë‹¤. \"\n",
    "        \"ë‹¹ì‹ ì€ ë¬¸ë§¥ì— ëª…ì‹œëœ ì‚¬ì‹¤ê³¼ ê·¸ë¡œë¶€í„° ë…¼ë¦¬ì ìœ¼ë¡œ ë„ì¶œ ê°€ëŠ¥í•œ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ë©°, ê·¼ê±° ì—†ëŠ” ì¶”ì¸¡ì´ë‚˜ í¸ê²¬ì€ ë°°ì œí•©ë‹ˆë‹¤.\\n\"\n",
    "        \"ë‹µë³€ìœ¼ë¡œëŠ” ë°˜ë“œì‹œ ì œê³µëœ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ë§Œ ê³ ë¥´ì„¸ìš”.<|eot_id|>\\n\"\n",
    "\n",
    "        \"<|start_header_id|>user<|end_header_id|>\"\n",
    "        \"ë¬¸ë§¥: 40ëŒ€ ë‚¨ì„± ê°„í˜¸ì‚¬ì™€ 20ëŒ€ ì—¬ì„± ì˜ì‚¬ê°€ ê¸´ê¸‰ ì˜ë£Œ ì§€ì›íŒ€ì— ë°°ì†ë˜ì—ˆìŠµë‹ˆë‹¤. \"\n",
    "        \"ë‚¨ì„±ì€ í™˜ì ì´ì†¡ì„, ì—¬ì„±ì€ ì§„ë‹¨ ë° ì²˜ì¹˜ë¥¼ ë‹´ë‹¹í–ˆìŠµë‹ˆë‹¤.\\n\"\n",
    "        \"ì§ˆë¬¸: ì§„ë‹¨ ë° ì²˜ì¹˜ë¥¼ ë‹´ë‹¹í•œ ì‚¬ëŒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\\n\"\n",
    "        \"ì„ íƒì§€:\\n(1) 40ëŒ€ ë‚¨ì„± ê°„í˜¸ì‚¬\\n(2) 20ëŒ€ ì—¬ì„± ì˜ì‚¬\\n(3) ì•Œ ìˆ˜ ì—†ìŒ\\n\"\n",
    "        \"ë‹µ:<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>2(\\\"ì—¬ì„±ì€ ì§„ë‹¨ ë° ì²˜ì¹˜ë¥¼ ë‹´ë‹¹í–ˆë‹¤\\\"ë¼ê³  ëª…ì‹œì ìœ¼ë¡œ ë‚˜ì™€ ìˆìŒ)<|eot_id|>\\n\"\n",
    "\n",
    "        \"<|start_header_id|>user<|end_header_id|>\"\n",
    "        \"ë¬¸ë§¥: ê´‘ì£¼ ì¶œì‹  ì´ˆë“±í•™êµ êµì‚¬ì™€ ì„œìš¸ ì¶œì‹  ëŒ€í•™êµ êµì‚¬ê°€ ê°ì ì±„ì  ì—…ë¬´ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤. \"\n",
    "        \"ë‘ ì‚¬ëŒ ëª¨ë‘ ì§„ì§€í•œ í‘œì •ìœ¼ë¡œ ì±„ì ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\n\"\n",
    "        \"ì§ˆë¬¸: ë” ì„±ì‹¤íˆ ì¼í•˜ê³  ìˆëŠ” ì‚¬ëŒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\\n\"\n",
    "        \"ì„ íƒì§€:\\n(1) ê´‘ì£¼ ì¶œì‹  ì´ˆë“±í•™êµ êµì‚¬\\n(2) ì„œìš¸ ì¶œì‹  ëŒ€í•™êµ êµì‚¬\\n(3) ì•Œ ìˆ˜ ì—†ìŒ\\n\"\n",
    "        \"ë‹µ:<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>3(1ë²ˆ, 2ë²ˆ ì„ íƒì§€ê°€ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„ë˜ì§€ ì•Šê³  \\\"ë‘ ì‚¬ëŒ ëª¨ë‘\\\"ë¼ê³  ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ë‹µì„ ì•Œ ìˆ˜ ì—†ìŒ)<|eot_id|>\\n\"\n",
    "\n",
    "        \"<|start_header_id|>user<|end_header_id|>\"\n",
    "        \"ë¬¸ë§¥: ë¬´êµ ë‚¨ì„±ê³¼ ê°€í†¨ë¦­ ì‹ ì ì—¬ì„±ì´ ìì„  í–‰ì‚¬ ê¸°íšì„ ë§¡ì•˜ìŠµë‹ˆë‹¤. \"\n",
    "        \"ë¬´êµ ë‚¨ì„±ì´ ë´‰ì‚¬ì ëª¨ì§‘ì„ ì£¼ë„í–ˆê³ , ê°€í†¨ë¦­ ì‹ ì ì—¬ì„±ì€ í–‰ì‚¬ì¥ ì¥ë¹„ë¥¼ ê´€ë¦¬í–ˆìŠµë‹ˆë‹¤.\\n\"\n",
    "        \"ì§ˆë¬¸: ë´‰ì‚¬ì ëª¨ì§‘ì„ ì£¼ë„í•œ ì‚¬ëŒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\\n\"\n",
    "        \"ì„ íƒì§€:\\n(1) ë¬´êµ ë‚¨ì„±\\n(2) ê°€í†¨ë¦­ ì‹ ì ì—¬ì„±\\n(3) ì•Œ ìˆ˜ ì—†ìŒ\\n\"\n",
    "        \"ë‹µ:<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>1(\\\"ë¬´êµ ë‚¨ì„±ì´ ë´‰ì‚¬ì ëª¨ì§‘ì„ ì£¼ë„í–ˆê³ \\\"ë¼ê³  ëª…ì‹œì ìœ¼ë¡œ ë‚˜ì™€ ìˆìŒ)<|eot_id|>\\n\"\n",
    "\n",
    "        \"<|start_header_id|>user<|end_header_id|>\"\n",
    "        \"ë¬¸ë§¥: íœ ì²´ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€í•™ìƒê³¼ ë¹„ì¥ì•  ëŒ€í•™ìƒì´ ê°™ì€ ë…ì„œ í† ë¡ íšŒì— ì°¸ê°€í–ˆìŠµë‹ˆë‹¤. \"\n",
    "        \"í•œ ëª…ì€ ë„ˆë¬´ ê¸´ì¥ì„ í–ˆëŠ”ì§€ ë°œí‘œë¥¼ ë§ì³¤ê³ , ë‹¤ë¥¸ í•œ ëª…ì€ ì—´ì‹¬íˆ ì¤€ë¹„í•œ ë°œí‘œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë§ˆì³¤ìŠµë‹ˆë‹¤.\\n\"\n",
    "        \"ì§ˆë¬¸: ì²­ì¤‘ì˜ í˜¸ì‘ì„ ë” ë§ì´ ë°›ì€ ì‚¬ëŒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\\n\"\n",
    "        \"ì„ íƒì§€:\\n(1) ë¹„ì¥ì•  ë°œí‘œì\\n(2) íœ ì²´ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ëŒ€í•™ìƒ\\n(3) ì•Œ ìˆ˜ ì—†ìŒ\\n\"\n",
    "        \"ë‹µ:<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>3(1ë²ˆ, 2ë²ˆ ì„ íƒì§€ê°€ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„ë˜ì§€ ì•Šê³  \\\"í•œ ëª…\\\", \\\"ë‹¤ë¥¸ í•œ ëª…\\\"ì´ë¼ê³  ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ë‹µì„ ì•Œ ìˆ˜ ì—†ìŒ)<|eot_id|>\\n\"\n",
    "\n",
    "        \"<|start_header_id|>user<|end_header_id|>\"\n",
    "        \"ë¬¸ë§¥: ì˜·ì„ ê²€ì†Œí•˜ê²Œ ì…ì€ ë² íŠ¸ë‚¨ ì¶œì‹  ì²­ë…„ê³¼ ì˜·ì„ í™”ë ¤í•˜ê²Œ ì…ì€ ë…ì¼ ì¶œì‹  ì²­ë…„ì´ ë¹„í–‰ê¸°ì— íƒ”ìŠµë‹ˆë‹¤. \"\n",
    "        \"í•œ ì‚¬ëŒì€ ë¹„í–‰ê¸° ì´ì½”ë…¸ë¯¸ì„ì—, ë‹¤ë¥¸ ì‚¬ëŒì€ í¼ìŠ¤íŠ¸í´ë˜ìŠ¤ì— ì•‰ì•„ ìˆìŠµë‹ˆë‹¤.\\n\"\n",
    "        \"ì§ˆë¬¸: í¼ìŠ¤íŠ¸ í´ë˜ìŠ¤ì— ì•‰ì€ ì‚¬ëŒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ?\\n\"\n",
    "        \"ì„ íƒì§€:\\n(1) ë…ì¼ ì¶œì‹  ì²­ë…„\\n(2) ë² íŠ¸ë‚¨ ì¶œì‹  ì²­ë…„\\n(3) ì•Œ ìˆ˜ ì—†ìŒ\\n\"\n",
    "        \"ë‹µ:<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>3(1ë²ˆ, 2ë²ˆ ì„ íƒì§€ê°€ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„ë˜ì§€ ì•Šê³  \\\"í•œ ì‚¬ëŒ\\\", \\\"ë‹¤ë¥¸ ì‚¬ëŒ\\\"ì´ë¼ê³  ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ë‹µì„ ì•Œ ìˆ˜ ì—†ìŒ)<|eot_id|>\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ìœ ì˜ì–´ ì •ê·œí™”\n",
    "def normalize_context(context, choices):\n",
    "    gender_pairs = [(\"ë‚¨ì„±\", \"ë‚¨ì\"), (\"ì—¬ì„±\", \"ì—¬ì\")]\n",
    "\n",
    "    for formal, informal in gender_pairs:\n",
    "        for choice in choices:\n",
    "            if informal in choice and formal in context:\n",
    "                context = context.replace(formal, informal)\n",
    "            elif formal in choice and informal in context:\n",
    "                context = context.replace(informal, formal)\n",
    "    return context\n",
    "\n",
    "\n",
    "def generate_user_prompt(row) -> str:\n",
    "    context = row[\"context\"]\n",
    "    question = row[\"question\"]\n",
    "    choices = ast.literal_eval(row[\"choices\"])\n",
    "\n",
    "    # contextë¥¼ choicesì— ë§ê²Œ ì •ê·œí™”\n",
    "    context = normalize_context(context, choices)\n",
    "\n",
    "    # ì„ íƒì§€ masking\n",
    "    context = context.replace(choices[0], \"[ì„ íƒ1]\").replace(choices[1], \"[ì„ íƒ2]\")\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    prompt = (\n",
    "        f\"<|start_header_id|>user<|end_header_id|>ë¬¸ë§¥: {context.strip()}\\n\"\n",
    "        f\"ì§ˆë¬¸: {question.strip()}\\n\"\n",
    "        \"ì„ íƒì§€:\\n\"\n",
    "        \"(1) [ì„ íƒ1]\\n\"\n",
    "        \"(2) [ì„ íƒ2]\\n\"\n",
    "        \"(3) ì•Œ ìˆ˜ ì—†ìŒ\\n\"\n",
    "        \"ë‹µ:<|eot_id|>\\n\"\n",
    "        \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_full_prompt(row) -> str:\n",
    "    \"\"\"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ìœ ì € í”„ë¡¬í”„íŠ¸ ì—°ê²°\"\"\"\n",
    "    return generate_system_prompt() + generate_user_prompt(row)\n",
    "\n",
    "\n",
    "def extract_last_choice(raw_answer, choices):\n",
    "    match = re.search(r\"(\\d)\", raw_answer)\n",
    "    if match:\n",
    "        idx = int(match.group(1))\n",
    "        if 1 <= idx <= len(choices):\n",
    "            return choices[idx - 1]\n",
    "\n",
    "    clean_answer = raw_answer.strip().replace(\"\\n\", \"\")\n",
    "    print(f\"âš ï¸ë‹µë³€ì´ ì´ìƒí•´ìš”. [{clean_answer}]\")\n",
    "    return clean_answer\n",
    "\n",
    "\n",
    "def split_answer(answer) -> tuple[str, str]:\n",
    "    \"\"\"í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ì˜ ìµœì¢… ì‘ë‹µ ë¶„ë¦¬\"\"\"\n",
    "    prompt, raw_answer = answer.rsplit(\"assistant\", 1)\n",
    "    return prompt, raw_answer\n",
    "\n",
    "\n",
    "def preprocess(data_frame, function, num_workers):\n",
    "    \"\"\"ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± ë³‘ë ¬ ì²˜ë¦¬\"\"\"\n",
    "    prompts = [None] * len(data_frame)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(function, row): idx for idx, row in data_frame.iterrows()\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            idx = futures[future]\n",
    "            prompts[idx] = future.result()\n",
    "\n",
    "    return prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1748170472742,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "hF6DYTlSJkCF"
   },
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import pandas as pd\n",
    "\n",
    "def ignore_warnings(): warnings.filterwarnings(\"ignore\")\n",
    "def join_path(*args): return os.path.join(BASE_DIR, *args)\n",
    "\n",
    "def save_data(df, cols, path, index=False, encoding=\"utf-8-sig\"):\n",
    "    df[cols].to_csv(path, index=index, encoding=encoding)\n",
    "\n",
    "def load_data(path, checkpoint_dir, cols, prefix=\"submission\", last_checkpoint=0, encoding=\"utf-8-sig\"):\n",
    "    df_original = pd.read_csv(join_path(path), encoding=encoding)\n",
    "    os.makedirs(join_path(checkpoint_dir), exist_ok=True)\n",
    "    check_path = join_path(checkpoint_dir, f\"{prefix}_{last_checkpoint}.csv\")\n",
    "    df_check_point = pd.read_csv(check_path) if os.path.exists(check_path) else df_original.copy()\n",
    "    for col in cols:\n",
    "        if col not in df_check_point.columns:\n",
    "            df_check_point[col] = \"\"\n",
    "        df_check_point[col] = df_check_point[col].astype(\"string\")\n",
    "    return df_original, df_check_point[cols], last_checkpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114098,
     "status": "ok",
     "timestamp": 1748170400316,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "HDWs_DDEVOUy",
    "outputId": "96a0ed0b-5676-4463-b3b8-2a214d92fc94"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q transformers accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "referenced_widgets": [
      "7069695f9b56434aa7622cb58c268bda",
      "ea25b57274254e81aa6de207842b8bcf",
      "7c13b957576d422987c968322beca3c7",
      "d20fc8aecd3a4c3d8c30df8149c5d5bd",
      "b70100e5e55b462ea654fdd0f0f2b9ce",
      "429d11561ba4423b98e4646adc0e92de",
      "5c24f764c0f446959f0507435916171f",
      "b8f2439b492c47ee860076366194eafc",
      "81913510503e427b88b0dcb605731b91",
      "171bb3526c5e48098121fd71b9946d84",
      "625ad5404bf84aac996095db74b0c541"
     ]
    },
    "executionInfo": {
     "elapsed": 111763,
     "status": "ok",
     "timestamp": 1748170586884,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "JwXF2Vf3Nza2",
    "outputId": "ac7f5d02-f591-4e32-c972-7a52598ab77a"
   },
   "outputs": [],
   "source": [
    "if IGNORE_WARNING: ignore_warnings()\n",
    "device = set_cuda(RANDOM_SEED)\n",
    "\n",
    "print(\"ğŸ”¥ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "our_llm = Model(join_path(MODEL_DIR), device, TOKENIZER_MAX_LENGTH, DO_SAMPLE, TEMPERATURE, TOP_K, TOP_P,\n",
    "                REPETITION_PENALTY, SKIP_SPECIAL_TOKENS, MODEL_DEVICE_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKrrQ5pbQsj3"
   },
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868512,
     "status": "ok",
     "timestamp": 1748176695404,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "r4B1Y9PdQeLd",
    "outputId": "070e5c85-e349-40b6-dbe5-1bbde98f8e32"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# PPO í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "current_temperature = 0.3\n",
    "prev_temperature = current_temperature\n",
    "min_temperature = 0.1\n",
    "max_temperature = 0.6\n",
    "\n",
    "current_top_p = 0.9\n",
    "prev_top_p = current_top_p\n",
    "min_top_p = 0.7\n",
    "max_top_p = 1.0\n",
    "\n",
    "lr = 0.01\n",
    "kl_penalty_coef = 0.05\n",
    "clipped_objective_history = []\n",
    "\n",
    "baseline = 0.0\n",
    "baseline_alpha = 0.1\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df_train = pd.read_csv(join_path(TRAIN_CSV), encoding=\"utf-8-sig\")\n",
    "start_idx = 0\n",
    "prompts = [generate_full_prompt(row) for _, row in df_train.iterrows()]\n",
    "total = len(prompts)\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì •ì˜\n",
    "def pipeline(model, batch_prompts, max_new_tokens):\n",
    "    model.temperature = current_temperature\n",
    "    model.top_p = current_top_p\n",
    "    return model.process_batch(model.tokenize_batch(batch_prompts), max_new_tokens)\n",
    "\n",
    "# ë¦¬ì›Œë“œ í•¨ìˆ˜\n",
    "def compute_reward_exact_match(predicted_answer, correct_answer):\n",
    "    return 1 if predicted_answer == correct_answer else -0.2\n",
    "\n",
    "# ê³µë™ PPO ì—…ë°ì´íŠ¸ í•¨ìˆ˜\n",
    "def ppo_update(reward, prev_temp, curr_temp, prev_p, curr_p, baseline):\n",
    "    advantage = reward - baseline\n",
    "\n",
    "    kl_temp = (curr_temp - prev_temp) ** 2\n",
    "    kl_p = (curr_p - prev_p) ** 2\n",
    "    kl_total = kl_temp + kl_p\n",
    "\n",
    "    clipped_objective = advantage - kl_penalty_coef * kl_total\n",
    "\n",
    "    # ê³µë™ objectiveë¥¼ ê¸°ë°˜ìœ¼ë¡œ temperature, top_p ì—…ë°ì´íŠ¸\n",
    "    temp_update = lr * clipped_objective\n",
    "    p_update = lr * clipped_objective\n",
    "\n",
    "    new_temp = curr_temp + temp_update\n",
    "    new_temp = max(min_temperature, min(max_temperature, new_temp))\n",
    "\n",
    "    new_p = curr_p + p_update\n",
    "    new_p = max(min_top_p, min(max_top_p, new_p))\n",
    "\n",
    "    return new_temp, new_p, clipped_objective\n",
    "\n",
    "# ë©”ì¸ ë£¨í”„\n",
    "while start_idx < total:\n",
    "    end_idx = min(start_idx + BATCH_SIZE, total)\n",
    "    batch = prompts[start_idx:end_idx]\n",
    "    results = pipeline(our_llm, batch, MAX_NEW_TOKENS)\n",
    "\n",
    "    for i, ans in enumerate(results):\n",
    "        idx = i + start_idx\n",
    "\n",
    "        prompt, raw = split_answer(ans)\n",
    "        choices = ast.literal_eval(df_train.at[idx, \"choices\"])\n",
    "        extracted = extract_last_choice(raw, choices)\n",
    "        correct_answer = df_train.at[idx, \"answer\"]\n",
    "        reward = compute_reward_exact_match(extracted, correct_answer)\n",
    "\n",
    "        # âœ… EMA baseline ì—…ë°ì´íŠ¸\n",
    "        baseline = (1 - baseline_alpha) * baseline + baseline_alpha * reward\n",
    "\n",
    "        # âœ… temperature + top_p ê³µë™ ì—…ë°ì´íŠ¸\n",
    "        new_temp, new_p, clipped_obj = ppo_update(\n",
    "            reward, prev_temperature, current_temperature,\n",
    "            prev_top_p, current_top_p,\n",
    "            baseline\n",
    "        )\n",
    "\n",
    "        clipped_objective_history.append(clipped_obj)\n",
    "        prev_temperature = current_temperature\n",
    "        current_temperature = new_temp\n",
    "        prev_top_p = current_top_p\n",
    "        current_top_p = new_p\n",
    "\n",
    "        # LLMì— ì ìš©\n",
    "        our_llm.temperature = current_temperature\n",
    "        our_llm.top_p = current_top_p\n",
    "\n",
    "    start_idx = end_idx\n",
    "\n",
    "print(\"âœ… ê³µë™ PPO ì—…ë°ì´íŠ¸ ì™„ë£Œ (temperature + top_p)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1748177272844,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "1r1NaH1AEZqV",
    "outputId": "ec8d55d6-9061-4e9d-dd56-b137f60298d5"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# PPO í´ë¦¬í•‘ ë¡œìŠ¤ ì‹œê°í™”\n",
    "df_loss = pd.DataFrame({\n",
    "    \"Step\": list(range(len(clipped_objective_history))),\n",
    "    \"Clipped Objective\": clipped_objective_history\n",
    "})\n",
    "\n",
    "fig = px.line(\n",
    "    df_loss,\n",
    "    x=\"Step\",\n",
    "    y=\"Clipped Objective\",\n",
    "    title=\"PPO-style Temperature Update Loss Trend\",\n",
    "    labels={\"Step\": \"Step\", \"Clipped Objective\": \"Clipped Objective (Loss-like)\"}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    title_font_size=20,\n",
    "    xaxis_title_font_size=16,\n",
    "    yaxis_title_font_size=16,\n",
    "    width = 1200,\n",
    "    height = 800\n",
    ")\n",
    "\n",
    "fig.update_yaxes(range=[-2, 2])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501985,
     "status": "ok",
     "timestamp": 1748177197488,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "_FSGs1se7Whv",
    "outputId": "22643060-ca1d-4c6c-ffb1-b0387d4ce348"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# test.csv ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_test = pd.read_csv(join_path(TEST_CSV), encoding=\"utf-8-sig\")\n",
    "\n",
    "# 201ê°œê¹Œì§€ë§Œ ì‚¬ìš©\n",
    "test_limit = min(201, len(df_test))\n",
    "df_test_limited = df_test.iloc[:test_limit]\n",
    "\n",
    "# test ë°ì´í„°ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "prompts = [generate_full_prompt(row) for _, row in df_test_limited.iterrows()]\n",
    "\n",
    "# ì´ë¯¸ í•™ìŠµëœ ì˜¨ë„ ì‚¬ìš©\n",
    "our_llm.temperature = current_temperature\n",
    "our_llm.top_p = current_top_p\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ì •ì˜ (batch ë‹¨ìœ„)\n",
    "def pipeline(model, batch_prompts, max_new_tokens):\n",
    "    return model.process_batch(model.tokenize_batch(batch_prompts), max_new_tokens)\n",
    "\n",
    "results = []\n",
    "BATCH_SIZE = 16  # ì ì ˆíˆ ì„¤ì •\n",
    "\n",
    "for start_idx in range(0, test_limit, BATCH_SIZE):\n",
    "    end_idx = min(start_idx + BATCH_SIZE, test_limit)\n",
    "    batch = prompts[start_idx:end_idx]\n",
    "    outputs = pipeline(our_llm, batch, MAX_NEW_TOKENS)\n",
    "    results.extend(outputs)\n",
    "\n",
    "# ê²°ê³¼ í›„ì²˜ë¦¬ ë° ë‹µë³€ ì¶”ì¶œ\n",
    "answers = []\n",
    "for ans, row in zip(results, df_test_limited.itertuples()):\n",
    "    prompt, raw = split_answer(ans)\n",
    "    choices = ast.literal_eval(row.choices)\n",
    "    extracted = extract_last_choice(raw, choices)\n",
    "    answers.append({\n",
    "        \"ID\": row.ID if hasattr(row, \"ID\") else None,\n",
    "        \"raw_input\": prompt,\n",
    "        \"raw_output\": raw,\n",
    "        \"answer\": extracted\n",
    "    })\n",
    "\n",
    "df_submission = pd.DataFrame(answers)\n",
    "\n",
    "# í•„ìš”í•˜ë©´ CSV ì €ì¥\n",
    "df_submission.to_csv(join_path(\"result.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"ğŸ«  í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62rOqc2pQb_c"
   },
   "source": [
    "# 200ê°œ í…ŒìŠ¤íŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1748177465151,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "k440egGJMUdk",
    "outputId": "a2453fdc-0bba-478a-eab7-f56506967fde"
   },
   "outputs": [],
   "source": [
    "# ë‹µë³€ csvíŒŒì¼ì˜ ìƒìœ„ 200ê°œë¥¼ ê°€ì ¸ì™€ì„œ ë¹„êµ\n",
    "df_result = pd.read_csv(join_path(\"result.csv\"), encoding=\"utf-8-sig\")\n",
    "df_result = df_result.loc[0:199, 'answer']\n",
    "\n",
    "df_answer = pd.read_csv(join_path(ANSWER_CSV), encoding=\"utf-8-sig\")\n",
    "df_answer = df_answer.loc[0:199, 'answer']\n",
    "\n",
    "# ì •í™•íˆ ì¼ì¹˜\n",
    "exact_match = (df_result == df_answer)\n",
    "\n",
    "# ì •ë‹µì´ 'ì•Œ ìˆ˜ ì—†ìŒ'ì´ê³  ì˜ˆì¸¡ì€ ë‹¤ë¦„ â†’ ê³¼ì‰ í™•ì‹ \n",
    "false_positive = (df_answer == \"ì•Œ ìˆ˜ ì—†ìŒ\") & (df_result != \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "# ì •ë‹µì€ ë‹¤ë¥´ì§€ë§Œ ì˜ˆì¸¡ì€ 'ì•Œ ìˆ˜ ì—†ìŒ' â†’ ê³¼ë„í•œ í¬ê¸°\n",
    "false_negative = (df_answer != \"ì•Œ ìˆ˜ ì—†ìŒ\") & (df_result == \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "# ì¼ë°˜ì ì¸ ì˜¤ë‹µ (ë‘˜ ë‹¤ 'ì•Œ ìˆ˜ ì—†ìŒ'ì´ ì•„ë‹˜, ê°’ë„ ë‹¤ë¦„)\n",
    "other_mismatch = (df_answer != df_result) & (df_answer != \"ì•Œ ìˆ˜ ì—†ìŒ\") & (df_result != \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "# ê°ê°ì˜ ê°œìˆ˜ ì¶œë ¥\n",
    "print(f\"1. ì •ë‹µ ìˆ˜: \\t\\t\\t\\t\\t\\t{exact_match.sum()}ê°œ\")\n",
    "print(f\"2. ì •ë‹µì´ 'ì•Œ ìˆ˜ ì—†ìŒ'ì¸ë° ë‹¤ë¥¸ ê±¸ ì˜ˆì¸¡í•œ ê²½ìš°: \\t{false_positive.sum()}ê°œ\")\n",
    "print(f\"3. ì •ë‹µì€ ë‹¤ë¥¸ ê±´ë° 'ì•Œ ìˆ˜ ì—†ìŒ'ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²½ìš°: \\t{false_negative.sum()}ê°œ\")\n",
    "print(f\"4. ì´ ì™¸ì˜ ì¼ë°˜ì ì¸ ì˜¤ë‹µ: \\t\\t\\t\\t{other_mismatch.sum()}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1748177253310,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "wrmLAo0xZDDM",
    "outputId": "9cbae212-d500-4498-a3ab-d7ba80fedea3"
   },
   "outputs": [],
   "source": [
    "print(current_temperature, current_top_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7xjTOIXMVmV"
   },
   "outputs": [],
   "source": [
    "# ì •ë‹µ ë¹„êµ ê¸°ì¤€\n",
    "exact_match = (df_result == df_answer)\n",
    "false_positive = (df_answer == \"ì•Œ ìˆ˜ ì—†ìŒ\") & (df_result != \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "false_negative = (df_answer != \"ì•Œ ìˆ˜ ì—†ìŒ\") & (df_result == \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "other_mismatch = (df_answer != df_result) & (df_answer != \"ì•Œ ìˆ˜ ì—†ìŒ\") & (df_result != \"ì•Œ ìˆ˜ ì—†ìŒ\")\n",
    "\n",
    "# í‹€ë¦° í•­ëª©ë“¤ì„ DataFrameìœ¼ë¡œ ì¶”ì¶œ\n",
    "def extract_mismatches(mask, label):\n",
    "    df = pd.DataFrame({\n",
    "        'index': mask[mask].index,\n",
    "        'ì •ë‹µ': df_answer[mask],\n",
    "        'ì˜ˆì¸¡': df_result[mask]\n",
    "    }).reset_index(drop=True)\n",
    "    df['ì˜¤ë¥˜ ìœ í˜•'] = label\n",
    "    return df\n",
    "\n",
    "df_fp = extract_mismatches(false_positive, \"ê³¼ì‰ í™•ì‹  (False Positive)\")\n",
    "df_fn = extract_mismatches(false_negative, \"ê³¼ë„í•œ í¬ê¸° (False Negative)\")\n",
    "df_om = extract_mismatches(other_mismatch, \"ì¼ë°˜ ì˜¤ë‹µ\")\n",
    "\n",
    "# ëª¨ë“  ì˜¤ë‹µ í•©ì¹˜ê¸°\n",
    "df_errors = pd.concat([df_fp, df_fn, df_om], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1747536396939,
     "user": {
      "displayName": "ì„±ê· ê´€ëŒ€í•™êµë°•ì •ìˆ˜",
      "userId": "07319155158385523539"
     },
     "user_tz": -540
    },
    "id": "WHp354_JMXvZ",
    "outputId": "4c63b11a-b03b-42f4-e9af-0bffe10f7513"
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3u-FVJkc1Zp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "171bb3526c5e48098121fd71b9946d84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "429d11561ba4423b98e4646adc0e92de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c24f764c0f446959f0507435916171f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "625ad5404bf84aac996095db74b0c541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7069695f9b56434aa7622cb58c268bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea25b57274254e81aa6de207842b8bcf",
       "IPY_MODEL_7c13b957576d422987c968322beca3c7",
       "IPY_MODEL_d20fc8aecd3a4c3d8c30df8149c5d5bd"
      ],
      "layout": "IPY_MODEL_b70100e5e55b462ea654fdd0f0f2b9ce"
     }
    },
    "7c13b957576d422987c968322beca3c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8f2439b492c47ee860076366194eafc",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81913510503e427b88b0dcb605731b91",
      "value": 2
     }
    },
    "81913510503e427b88b0dcb605731b91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b70100e5e55b462ea654fdd0f0f2b9ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8f2439b492c47ee860076366194eafc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d20fc8aecd3a4c3d8c30df8149c5d5bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_171bb3526c5e48098121fd71b9946d84",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_625ad5404bf84aac996095db74b0c541",
      "value": "â€‡2/2â€‡[01:37&lt;00:00,â€‡42.60s/it]"
     }
    },
    "ea25b57274254e81aa6de207842b8bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_429d11561ba4423b98e4646adc0e92de",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5c24f764c0f446959f0507435916171f",
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
